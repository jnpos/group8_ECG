{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnpos/group8_ECG/blob/Experimental-set-up/ECG_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load data and packages**"
      ],
      "metadata": {
        "id": "RALEwSfkRVGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYsZqFpNnCHH",
        "outputId": "a5d7a098-79b9-455a-a8ac-662bad5db4d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tm10007_ml' already exists and is not an empty directory.\n",
            "The number of samples: 827\n",
            "The number of columns: 9001\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!git clone https://github.com/jveenland/tm10007_ml.git\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "with zipfile.ZipFile('/content/tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/tm10007_ml/ecg')\n",
        "\n",
        "data = pd.read_csv('/content/tm10007_ml/ecg/ecg_data.csv', index_col=0)\n",
        "\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Packages\n",
        "import numpy as np \n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from scipy.stats import shapiro\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import ElasticNet, Lasso, ElasticNetCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split data into input and output**"
      ],
      "metadata": {
        "id": "xYjhz2AnRwW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Niet handiger om preprocessing (incl deleting missing data en scaling) te doen vóór data splitten?"
      ],
      "metadata": {
        "id": "uJidu6wV7ob6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find column with label \n",
        "bool_cols = [col for col in data \n",
        "             if np.isin(data[col].dropna().unique(), [0, 1]).all()]\n",
        "loc_label = data.columns.get_loc('label')\n",
        "\n",
        "# Determine data and output \n",
        "y = data['label']\n",
        "x = pd.DataFrame()\n",
        "x = data.drop(data.columns[loc_label],axis=1)"
      ],
      "metadata": {
        "id": "1MUfgS9jR2Qk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**"
      ],
      "metadata": {
        "id": "LsJEhl71SHw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Delete samples with missing data**"
      ],
      "metadata": {
        "id": "IieMu5mWSOuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deleted_patients = []\n",
        "zero_samples = []\n",
        "zero_counts = []\n",
        "\n",
        "# Find patients (samples) with zero-padded ECG lead(s) (number of zeros for 1 lead = 750)\n",
        "for i in range(len(x)):\n",
        "  num_zeros = (x.iloc[i] == 0).sum()\n",
        "  if (num_zeros/750 >= 1) & (num_zeros%750 == 0):      # control if number of zeros is divisible by 750 and therefore zero-padded missing data and not relevant actual data\n",
        "    deleted_patients.append(i)\n",
        "    zero_samples.append(\"Sample_\" + str(i))\n",
        "    zero_counts.append(num_zeros)\n",
        "\n",
        "# Delete patients with missing lead data from dataset\n",
        "x_dropped = x.drop(deleted_patients)\n",
        "x_dropped = x_dropped.reset_index(drop=True)\n",
        "y_dropped = y.drop(deleted_patients)\n",
        "y_dropped = y_dropped.reset_index(drop=True)\n",
        "table = pd.DataFrame({'Sample ID': zero_samples, 'Zero count': zero_counts})\n",
        "\n",
        "# Return table from patients that were deleted and give resultant number of samples and columns in final dataset\n",
        "print(table)\n",
        "print(f'The number of samples: {len(x_dropped.index)}')\n",
        "print(f'The number of columns: {len(x_dropped.columns)}')"
      ],
      "metadata": {
        "id": "a9ceE2a5SUmT",
        "outputId": "a38b25f2-927d-4e94-89d6-732ff1be681b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sample ID  Zero count\n",
            "0   Sample_177         750\n",
            "1   Sample_251         750\n",
            "2   Sample_269         750\n",
            "3   Sample_321         750\n",
            "4   Sample_323         750\n",
            "5   Sample_385         750\n",
            "6   Sample_434         750\n",
            "7   Sample_446         750\n",
            "8   Sample_537         750\n",
            "9   Sample_542         750\n",
            "10  Sample_575         750\n",
            "11  Sample_601         750\n",
            "12  Sample_784         750\n",
            "13  Sample_790         750\n",
            "The number of samples: 813\n",
            "The number of columns: 9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data in train and test set**"
      ],
      "metadata": {
        "id": "FC6ID5qg6A9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split test and trainingsdata and print shape of resulting trainset\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_dropped, y_dropped,test_size=0.25,random_state=0,stratify=y_dropped)\n",
        "\n",
        "print(f'Shape of training set x_train: {x_train.shape}')"
      ],
      "metadata": {
        "id": "o6dVsyJK6DbP",
        "outputId": "6555091e-553f-4e80-b386-b3ab8a03cdf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training set x_train: (609, 9000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaling**"
      ],
      "metadata": {
        "id": "4GOFkb615y6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling van x_train; N.B. MOET DIT NIET VOOR X_TEST, Y_TRAIN EN Y_TEST OOK GEBEUREN?\n",
        "scaler = preprocessing.RobustScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = pd.DataFrame(scaler.transform(x_train))"
      ],
      "metadata": {
        "id": "T2I8XRRh52MU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test if data is normally distributed**"
      ],
      "metadata": {
        "id": "VUBPMqv26tHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if data is normally distributed and print result \n",
        "amount_normallydistributed = 0\n",
        "\n",
        "for column in x_train.columns:\n",
        "  result = shapiro(x_train[column])\n",
        "  normallydistributed = result.pvalue > 0.05\n",
        "  amount_normallydistributed += normallydistributed \n",
        "  \n",
        "print(amount_normallydistributed, \"features are normally distributed features\")"
      ],
      "metadata": {
        "id": "9ZpE5Fjv6yPu",
        "outputId": "5073050e-92d5-4123-bda5-59b502be4d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 features are normally distributed features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature selection**"
      ],
      "metadata": {
        "id": "O9jtS3rI7ZNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Univariate**"
      ],
      "metadata": {
        "id": "xWx9Qdny7zyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply univariate feature selection and print resulting shape of train dataset\n",
        "selector = SelectKBest(f_classif, k=\"all\")\n",
        "selector.fit(x_train,y_train)\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "scores /= scores.max()\n",
        "\n",
        "dataframe = pd.DataFrame()\n",
        "dataframe = selector.pvalues_\n",
        "\n",
        "# print(len(selector.pvalues_[selector.pvalues_<0.05]))       # waarvoor dient deze regel?\n",
        "\n",
        "fs = SelectKBest(score_func=f_classif, k=len(selector.pvalues_[selector.pvalues_<0.05]))\n",
        "X_univariate = fs.fit_transform(x_train, y_train)\n",
        "print(f'Resulting x_train after univariate feature selection: {X_univariate.shape}')"
      ],
      "metadata": {
        "id": "qTdpScJD8sPG",
        "outputId": "5b9bf83d-b3b0-4f43-e7f4-fc6358976e97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resulting x_train after univariate feature selection: (609, 855)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elastic Net (EN) regression**"
      ],
      "metadata": {
        "id": "P3A5VOy--Y1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply elastic net regression feature selection and print resulting shape of train dataset\n",
        "regr_alpha_ = 0.3858647907662583\n",
        "\n",
        "ENreg = ElasticNet(alpha=regr_alpha_, l1_ratio=0.05).fit(x_train,y_train)\n",
        "model_ENreg = SelectFromModel(ENreg, prefit=True)\n",
        "X_ENreg = model_ENreg.transform(x_train)\n",
        "print(f'Resulting x_train after EN regression feature selection: {X_ENreg.shape}')"
      ],
      "metadata": {
        "id": "vIy3a2bD-bxZ",
        "outputId": "2e1f7e07-8aaf-490a-bd9c-4ecd630495d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resulting x_train after EN regression feature selection: (609, 172)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature transformation**"
      ],
      "metadata": {
        "id": "mRUdqw7NAZZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Principal Component Analysis (PCA)**"
      ],
      "metadata": {
        "id": "f9E6UXF5__wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In case of decision tree, feature amount was still too high after univariate feature selection\n",
        "# Principal Component Analysis is therefore applied to reduce amount of features to smaller amount of components\n",
        "X_univariate = pd.DataFrame(X_univariate)\n",
        "n_samples = len(X_univariate)\n",
        "n_features = len(X_univariate.columns)\n",
        "n_features = min((n_samples//2), n_features)\n",
        "\n",
        "p = PCA(n_components=n_features)\n",
        "p = p.fit(X_univariate)\n",
        "X_pca = p.transform(X_univariate)\n",
        "\n",
        "print(f'Resulting x_train after univariate feature selection and PCA feature transformation: {X_pca.shape}')"
      ],
      "metadata": {
        "id": "5f_a8VTyALw3",
        "outputId": "9bfdba74-70e8-49ff-a5f7-e7689d57782c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resulting x_train after univariate feature selection and PCA feature transformation: (609, 304)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot learning curves for classifiers with default hyperparameter settings**"
      ],
      "metadata": {
        "id": "RVLDIIWMC3PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define f_beta as a performance scorer\n",
        "# Beta < 1 lends more weight to precision, while beta > 1 favors recall\n",
        "f_beta = make_scorer(fbeta_score, beta=2)"
      ],
      "metadata": {
        "id": "W9na7XNHDMhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classifier: Decision Tree (DT)**"
      ],
      "metadata": {
        "id": "oujy4rZTC-xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = tree.DecisionTreeClassifier(random_state=0)"
      ],
      "metadata": {
        "id": "49aSzskIC-LC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}