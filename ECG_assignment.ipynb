{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnpos/group8_ECG/blob/Results/ECG_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jveenland/tm10007_ml.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8iRqJzPriLC",
        "outputId": "4c2be62a-d7a8-4741-bdd4-b4a9027abaac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tm10007_ml'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Unpacking objects: 100% (83/83), 67.99 MiB | 8.81 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "from sklearn import metrics\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Metrics\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import mean_absolute_error\n",
        "# from sklearn.metrics import r2_score\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "047Gr7IytEXy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYsZqFpNnCHH",
        "outputId": "71f8f2f0-9de2-4244-dbe8-e3b0d6d9536f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 827\n",
            "The number of columns: 9001\n"
          ]
        }
      ],
      "source": [
        "with zipfile.ZipFile('/content/tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/tm10007_ml/ecg')\n",
        "\n",
        "data = pd.read_csv('/content/tm10007_ml/ecg/ecg_data.csv', index_col=0)\n",
        "\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split input and output data:**"
      ],
      "metadata": {
        "id": "EhdR607ik017"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find column with label \n",
        "bool_cols = [col for col in data \n",
        "             if np.isin(data[col].dropna().unique(), [0, 1]).all()]\n",
        "loc_label = data.columns.get_loc('label')\n",
        "\n",
        "# Determine data and output \n",
        "y = data['label']\n",
        "x = pd.DataFrame()\n",
        "x = data.drop(data.columns[loc_label],axis=1)\n"
      ],
      "metadata": {
        "id": "q7ySkT_1rge5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check for missing data & remove samples with missing data:**"
      ],
      "metadata": {
        "id": "8tARYNCAebL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete patients (samples) with missing data\n",
        "deleted_patients = []\n",
        "zero_samples = []\n",
        "num_zeros = []\n",
        "zero_counts = []\n",
        "eenvariabele = []\n",
        "print(len(x))\n",
        "for i in range(len(x)):\n",
        "  num_zeros = (x.iloc[i] == 0).sum()\n",
        "  if (num_zeros/750 >= 1) & (num_zeros%750 == 0):                   # met deze regel controleer je of het aantal 0'en overeenkomt met het aantal frequentie features dat in 1 lead zit\n",
        "    deleted_patients.append(i)\n",
        "    zero_samples.append(\"Sample_\" + str(i))\n",
        "    zero_counts.append(num_zeros)\n",
        "\n",
        "x_dropped = x.drop(deleted_patients)\n",
        "x_dropped = x_dropped.reset_index(drop=True)\n",
        "y_dropped = y.drop(deleted_patients)\n",
        "y_dropped = y_dropped.reset_index(drop=True)\n",
        "table = pd.DataFrame({'Sample ID': zero_samples, 'Zero count': zero_counts})\n",
        "\n",
        "print(table)\n",
        "print(f'The number of samples: {len(x_dropped.index)}')\n",
        "print(f'The number of columns: {len(x_dropped.columns)}')"
      ],
      "metadata": {
        "id": "tTzin2A0eivv",
        "outputId": "3a6cb781-4926-4bdb-a538-b24f1252a0e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "827\n",
            "     Sample ID  Zero count\n",
            "0   Sample_177         750\n",
            "1   Sample_251         750\n",
            "2   Sample_269         750\n",
            "3   Sample_321         750\n",
            "4   Sample_323         750\n",
            "5   Sample_385         750\n",
            "6   Sample_434         750\n",
            "7   Sample_446         750\n",
            "8   Sample_537         750\n",
            "9   Sample_542         750\n",
            "10  Sample_575         750\n",
            "11  Sample_601         750\n",
            "12  Sample_784         750\n",
            "13  Sample_790         750\n",
            "The number of samples: 813\n",
            "The number of columns: 9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data in train and test:**"
      ],
      "metadata": {
        "id": "KRCSzTZjej2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split test and trainingsdata \n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_dropped, y_dropped,test_size=0.25,random_state=0,stratify=y_dropped)"
      ],
      "metadata": {
        "id": "jeomLTdFenH_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaling:**"
      ],
      "metadata": {
        "id": "ubWqftf7jVNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SCALEN\n",
        "scaler = preprocessing.RobustScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = pd.DataFrame(scaler.transform(x_train))\n",
        "\n",
        "# Niet fitten op test, alleen toepassen\n"
      ],
      "metadata": {
        "id": "pTeKfmHRI8I4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking if data is normally distributed:**\n"
      ],
      "metadata": {
        "id": "R0A0uDkswrg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if data is normally distributed  \n",
        "\n",
        "from scipy.stats import shapiro  \n",
        "shapiro(x_train)\n",
        "\n",
        "amount_normallydistributed = 0\n",
        "for column in x_train.columns:\n",
        "  result = shapiro(x_train[column])\n",
        "  normallydistributed = result.pvalue > 0.05\n",
        "  amount_normallydistributed += normallydistributed \n",
        "  \n",
        "print(amount_normallydistributed, \"features are normally distributed features\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-T7l12igocL",
        "outputId": "bad51b1c-964c-4c5c-ea76-a37fd5c695e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/scipy/stats/_morestats.py:1816: UserWarning: p-value may not be accurate for N > 5000.\n",
            "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 features are normally distributed features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature selection:**"
      ],
      "metadata": {
        "id": "Wejl1fh6jcmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection\n",
        "\n",
        "# Univariate & f_classif\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "selector = SelectKBest(f_classif,k=\"all\")\n",
        "selector.fit(x_train,y_train)\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "scores /= scores.max()\n",
        "\n",
        "dataframe = pd.DataFrame()\n",
        "dataframe = selector.pvalues_\n",
        "\n",
        "print(len(selector.pvalues_[selector.pvalues_<0.05]))\n",
        "\n",
        "fs = SelectKBest(score_func=f_classif, k=len(selector.pvalues_[selector.pvalues_<0.05]))\n",
        "X_univariate = fs.fit_transform(x_train, y_train)\n",
        "print(f'result univariate: {X_univariate.shape}')\n",
        "\n",
        "# Elastic net\n",
        "from sklearn.linear_model import ElasticNet, Lasso, ElasticNetCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "#for i in np.arange(0.02,1,0.02):\n",
        "#regr = ElasticNetCV(cv=5, random_state=0)\n",
        "#regr.fit(x_train, y_train)\n",
        "#print(regr.alpha_)\n",
        "#print(regr.intercept_)\n",
        "regr_alpha_ = 0.3858647907662583\n",
        "\n",
        "ENreg = ElasticNet(alpha=regr_alpha_, l1_ratio=0.05).fit(x_train,y_train)\n",
        "model_ENreg = SelectFromModel(ENreg, prefit=True)\n",
        "x_ENreg = model_ENreg.transform(x_train)\n",
        "#print(f'result Elastic Net: {x_ENreg.shape}, met als i:{i}')\n",
        "print(f'result Elastic Net: {x_ENreg.shape}')\n"
      ],
      "metadata": {
        "id": "mFaLdfI9i5eP",
        "outputId": "05b6f9eb-c51d-47b6-847b-22872f1356cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "855\n",
            "result univariate: (609, 855)\n",
            "result Elastic Net: (609, 172)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA for decision tree features:**"
      ],
      "metadata": {
        "id": "zWgB_O64jZVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA for decision tree features for x_univariate\n",
        "X_univariate = pd.DataFrame(X_univariate)\n",
        "n_samples = len(X_univariate)\n",
        "n_features = len(X_univariate.columns)\n",
        "n_features = min((n_samples//2), n_features)\n",
        "\n",
        "p = PCA(n_components=n_features)\n",
        "p = p.fit(X_univariate)\n",
        "x_pca = p.transform(X_univariate)\n",
        "\n",
        "print(f'result pca: {x_pca.shape}')"
      ],
      "metadata": {
        "id": "nUTJsxovisgU",
        "outputId": "68df38c2-3989-4083-8360-01fd7ab19eea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result pca: (609, 304)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning curves with F2 without hyperparameter optimization**"
      ],
      "metadata": {
        "id": "yjk3vmaMbFUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "# define f_beta as a scorer\n",
        "# beta < 1 lends more weight to precision, while beta > 1 favors recall\n",
        "f_beta = make_scorer(fbeta_score, beta=2)\n",
        "\n",
        "tree = tree.DecisionTreeClassifier(random_state=0)\n",
        "l_svm = LinearSVC(random_state=0)\n",
        "svm = svm.SVC(random_state=0)\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 6), sharey=True)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": X_univariate,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"score_type\": \"both\",\n",
        "    \"n_jobs\": 4,\n",
        "    \"line_kw\": {\"marker\": \"o\"},\n",
        "    \"std_display_style\": \"fill_between\",\n",
        "    \"score_name\": \"f2\",\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "title = ['tree', 'RF', 'LSVM', 'SVM']\n",
        "\n",
        "common_params_tree = {\n",
        "    \"X\": x_pca,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"score_type\": \"both\",\n",
        "    \"n_jobs\": 4,\n",
        "    \"line_kw\": {\"marker\": \"o\"},\n",
        "    \"std_display_style\": \"fill_between\",\n",
        "    \"score_name\": \"f2\",\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "LearningCurveDisplay.from_estimator(tree, **common_params_tree, ax=ax[0])\n",
        "handles, label = ax[0].get_legend_handles_labels()\n",
        "ax[0].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
        "ax[0].set_title(f\"Learning Curve for {title[0]}\")\n",
        "\n",
        "for ax_idx, estimator in enumerate([rf, l_svm, svm],1):\n",
        "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
        "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
        "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
        "    ax[ax_idx].set_title(f\"Learning Curve for {title[ax_idx]}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5VbdYLW2y0yX",
        "outputId": "80e55b6c-5b06-4e08-8ff8-39456579b858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-fe884b4e52f3>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLearningCurveDisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m common_params = {\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \"\"\"\n\u001b[1;32m   1501\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfig_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[0m\u001b[1;32m   1503\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m                        \u001b[0mgridspec_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_ratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight_ratios\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gridspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         axs = gs.subplots(sharex=sharex, sharey=sharey, squeeze=squeeze,\n\u001b[0m\u001b[1;32m    907\u001b[0m                           subplot_kw=subplot_kw)\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/gridspec.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(self, sharex, sharey, squeeze, subplot_kw)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sharex\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msharex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sharey\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msharey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 axarr[row, col] = figure.add_subplot(\n\u001b[0m\u001b[1;32m    300\u001b[0m                     self[row, col], **subplot_kw)\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m             projection_class, pkw = self._process_projection_requirements(\n\u001b[1;32m    756\u001b[0m                 *args, **kwargs)\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojection_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_axes_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, *args, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterization_zorder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# funcs used to format x and y - fall back on major formatters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Also resets the scale to linear.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mspine\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m             \u001b[0mspine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_existing_data_limits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/spines.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# clear position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_adjust_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axes.labelpad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2501\u001b[0m         \u001b[0;31m# x in display coords, y in axes coords (to be updated at draw time by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[0;31m# _update_label_positions and _update_offset_text_position).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2503\u001b[0;31m         self.label.set(\n\u001b[0m\u001b[1;32m   2504\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[0mverticalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bottom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{cls.__qualname__}.set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;31m# Artist._update_set_signature_and_docstring() at the end of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0;31m# module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mlack\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprenormalization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaintain\u001b[0m \u001b[0mbackcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \"\"\"\n\u001b[0;32m-> 1223\u001b[0;31m         return self._update_props(\n\u001b[0m\u001b[1;32m   1224\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{cls.__name__}.set() got an unexpected keyword argument \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \"{prop_name!r}\")\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1197\u001b[0m                         raise AttributeError(\n\u001b[1;32m   1198\u001b[0m                             errfmt.format(cls=type(self), prop_name=k))\n\u001b[0;32m-> 1199\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mset_verticalalignment\u001b[0;34m(self, align)\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0malign\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'bottom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'baseline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'center_baseline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \"\"\"\n\u001b[0;32m-> 1259\u001b[0;31m         _api.check_in_list(\n\u001b[0m\u001b[1;32m   1260\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m'top'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bottom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'baseline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'center_baseline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m             align=align)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "from functools import partial\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "f_beta = make_scorer(fbeta_score, beta=2)\n",
        "# f2_scorer = make_scorer(partial(fbeta_score, beta=2), greater_is_better=True)\n",
        "\n",
        "tree = tree.DecisionTreeClassifier(random_state=0)\n",
        "l_svm = LinearSVC(random_state=0)\n",
        "svm = svm.SVC(random_state=0)\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": X_univariate,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"n_jobs\": 4,\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "common_params_tree = {\n",
        "    \"X\": x_pca,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"n_jobs\": 4,\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "# create a list of tuples containing classifier names and their instances\n",
        "classifiers = [(\"Decision Tree\", tree), (\"Random Forest\", rf), (\"Linear SVM\", l_svm), (\"SVM\", svm)]\n",
        "\n",
        "# create an empty DataFrame to store the results\n",
        "results_df = pd.DataFrame(columns=[\"Classifier\", \"Train Size\", \"Train Score\", \"Train Score Std\", \"Test Score\", \"Test Score Std\"])\n",
        "\n",
        "# loop through the classifiers\n",
        "for clf_name, clf in classifiers:\n",
        "    print(\"working on:\", clf_name)\n",
        "    # set the name of the classifier in the results DataFrame\n",
        "    results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n",
        "\n",
        "    # select the common params based on the classifier name\n",
        "    if clf_name == \"Decision Tree\":\n",
        "        common_params_sel = common_params_tree\n",
        "    else:\n",
        "        common_params_sel = common_params\n",
        "    \n",
        "    # run the learning curve for the classifier\n",
        "    train_size_abs, train_scores, test_scores = learning_curve(clf, **common_params_sel)\n",
        "\n",
        "    # add the scores to the results DataFrame\n",
        "    results_df.loc[len(results_df)-1, \"Train Size\"] = train_size_abs[-1]\n",
        "    results_df.loc[len(results_df)-1, \"Train Score\"] = train_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Train Score Std\"] = np.std(train_scores[-1, :])\n",
        "    results_df.loc[len(results_df)-1, \"Test Score\"] = test_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Test Score Std\"] = np.std(test_scores[-1, :])\n",
        "\n",
        "# print the results DataFrame\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "T0y3zbeq_2J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Not optimized classifiers + ENReg**"
      ],
      "metadata": {
        "id": "hMLuw-u104v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "# define f_beta as a scorer\n",
        "# beta < 1 lends more weight to precision, while beta > 1 favors recall\n",
        "f_beta = make_scorer(fbeta_score, beta=2)\n",
        "\n",
        "tree = tree.DecisionTreeClassifier(random_state=0)\n",
        "l_svm = LinearSVC(random_state=0)\n",
        "svm = svm.SVC(random_state=0)\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 6), sharey=True)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": x_ENreg,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"score_type\": \"both\",\n",
        "    \"n_jobs\": 4,\n",
        "    \"line_kw\": {\"marker\": \"o\"},\n",
        "    \"std_display_style\": \"fill_between\",\n",
        "    \"score_name\": \"f2\",\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "title = ['tree', 'RF', 'LSVM', 'SVM']\n",
        "\n",
        "common_params_tree = {\n",
        "    \"X\": x_ENreg,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"score_type\": \"both\",\n",
        "    \"n_jobs\": 4,\n",
        "    \"line_kw\": {\"marker\": \"o\"},\n",
        "    \"std_display_style\": \"fill_between\",\n",
        "    \"score_name\": \"f2\",\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "LearningCurveDisplay.from_estimator(tree, **common_params_tree, ax=ax[0])\n",
        "handles, label = ax[0].get_legend_handles_labels()\n",
        "ax[0].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
        "ax[0].set_title(f\"Learning Curve for {title[0]}\")\n",
        "\n",
        "for ax_idx, estimator in enumerate([rf, l_svm, svm],1):\n",
        "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
        "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
        "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
        "    ax[ax_idx].set_title(f\"Learning Curve for {title[ax_idx]}\")\n"
      ],
      "metadata": {
        "id": "1IQh24Lg-2kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "from functools import partial\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "tree = tree.DecisionTreeClassifier(random_state=0)\n",
        "l_svm = LinearSVC(random_state=0)\n",
        "svm = svm.SVC(random_state=0)\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": x_ENreg,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"n_jobs\": 4,\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "# create a list of tuples containing classifier names and their instances\n",
        "classifiers = [(\"Decision Tree\", tree), (\"Random Forest\", rf), (\"Linear SVM\", l_svm), (\"SVM\", svm)]\n",
        "\n",
        "# create an empty DataFrame to store the results\n",
        "results_df = pd.DataFrame(columns=[\"Classifier\", \"Train Size\", \"Train Score\", \"Train Score Std\", \"Test Score\", \"Test Score Std\"])\n",
        "\n",
        "# loop through the classifiers\n",
        "for clf_name, clf in classifiers:\n",
        "    print(\"working on:\", clf_name)\n",
        "    # set the name of the classifier in the results DataFrame\n",
        "    #new_row = pd.Series([clf_name, 0, 0, 0, 0, 0], index=results_df.columns)\n",
        "    #results_df = results_df.append([clf_name, 0, 0, 0, 0, 0], ignore_index=True)\n",
        "    # pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n",
        "    \n",
        "    # run the learning curve for the classifier\n",
        "    train_size_abs, train_scores, test_scores = learning_curve(clf, **common_params)\n",
        "\n",
        "    # add the scores to the results DataFrame\n",
        "    results_df.loc[len(results_df)-1, \"Train Size\"] = train_size_abs[-1]\n",
        "    results_df.loc[len(results_df)-1, \"Train Score\"] = train_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Train Score Std\"] = np.std(train_scores[-1, :])\n",
        "    results_df.loc[len(results_df)-1, \"Test Score\"] = test_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Test Score Std\"] = np.std(test_scores[-1, :])\n",
        "\n",
        "# print the results DataFrame\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "ilHq8I5N0gjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning curves with F2 and hyperparameter optimization**"
      ],
      "metadata": {
        "id": "0gmil1TcuoOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimized classifiers + univariate**\n"
      ],
      "metadata": {
        "id": "Od-tYqA1u8N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "# define f_beta as a scorer\n",
        "# beta < 1 lends more weight to precision, while beta > 1 favors recall\n",
        "f_beta = make_scorer(fbeta_score, beta=2)\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=0, splitter='best', min_weight_fraction_leaf=0.16666666666666666, min_samples_split=2, min_samples_leaf=6, max_features=None, criterion='entropy', class_weight='balanced')\n",
        "l_svm = LinearSVC(random_state=0, tol=100.0, penalty='l1', loss='squared_hinge', intercept_scaling=9, fit_intercept=True, dual=False, class_weight='balanced', C=0.01)\n",
        "svm = svm.SVC(random_state=0, tol=10.0, shrinking=False, probability=True, kernel='poly', gamma='scale', degree=0, coef0=-5, class_weight='balanced', cache_size=363, C=0.001)\n",
        "# Moet nog aangepast worden naar goede hyperparameters (icm met X_univariate) random_state=0:\n",
        "rf = RandomForestClassifier(random_state=0, warm_start=True, oob_score=True, n_estimators=555, min_weight_fraction_leaf=0.1875, min_samples_split=4, min_samples_leaf=8, max_features=None, criterion='entropy', class_weight='balanced', bootstrap=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 6), sharey=True)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": X_univariate,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"score_type\": \"both\",\n",
        "    \"n_jobs\": 4,\n",
        "    \"line_kw\": {\"marker\": \"o\"},\n",
        "    \"std_display_style\": \"fill_between\",\n",
        "    \"score_name\": \"f2\",\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "title = ['tree', 'RF', 'LSVM', 'SVM']\n",
        "\n",
        "common_params_tree = {\n",
        "    \"X\": x_pca,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"score_type\": \"both\",\n",
        "    \"n_jobs\": 4,\n",
        "    \"line_kw\": {\"marker\": \"o\"},\n",
        "    \"std_display_style\": \"fill_between\",\n",
        "    \"score_name\": \"f2\",\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "LearningCurveDisplay.from_estimator(tree, **common_params_tree, ax=ax[0])\n",
        "handles, label = ax[0].get_legend_handles_labels()\n",
        "ax[0].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
        "ax[0].set_title(f\"Learning Curve for {title[0]}\")\n",
        "\n",
        "for ax_idx, estimator in enumerate([rf, l_svm, svm],1):\n",
        "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
        "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
        "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
        "    ax[ax_idx].set_title(f\"Learning Curve for {title[ax_idx]}\")"
      ],
      "metadata": {
        "id": "yOx3JXsI49A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "from functools import partial\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "f_beta = make_scorer(fbeta_score, beta=2)\n",
        "# f2_scorer = make_scorer(partial(fbeta_score, beta=2), greater_is_better=True)\n",
        "tree = DecisionTreeClassifier(splitter='best', min_weight_fraction_leaf=0.16666666666666666, min_samples_split=2, min_samples_leaf=6, max_features=None, criterion='entropy', class_weight='balanced')\n",
        "l_svm = LinearSVC(random_state=0, tol=100.0, penalty='l1', loss='squared_hinge', intercept_scaling=9, fit_intercept=True, dual=False, class_weight='balanced', C=0.01)\n",
        "#moeten nog aangepast worden naar goede hyperparameters (met goede X_ENreg):\n",
        "svm = svm.SVC(random_state=0, tol=10.0, shrinking=False, probability=True, kernel='poly', gamma='scale', degree=0, coef0=-5, class_weight='balanced', cache_size=363, C=0.001)\n",
        "#Deze staat al wel goed:\n",
        "rf = RandomForestClassifier(random_state=0, warm_start=True, oob_score=True, n_estimators=795, min_weight_fraction_leaf=0.14583333333333331, min_samples_split=9, min_samples_leaf=5, max_features='log2', criterion='gini', class_weight='balanced', bootstrap=True)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": X_univariate,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"n_jobs\": 4,\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "common_params_tree = {\n",
        "    \"X\": x_pca,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"n_jobs\": 4,\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "# create a list of tuples containing classifier names and their instances\n",
        "classifiers = [(\"Decision Tree\", tree), (\"Random Forest\", rf), (\"Linear SVM\", l_svm), (\"SVM\", svm)]\n",
        "\n",
        "# create an empty DataFrame to store the results\n",
        "results_df = pd.DataFrame(columns=[\"Classifier\", \"Train Size\", \"Train Score\", \"Train Score Std\", \"Test Score\", \"Test Score Std\"])\n",
        "\n",
        "# loop through the classifiers\n",
        "for clf_name, clf in classifiers:\n",
        "    print(\"working on:\", clf_name)\n",
        "    # set the name of the classifier in the results DataFrame\n",
        "    results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n",
        "\n",
        "    # select the common params based on the classifier name\n",
        "    if clf_name == \"Decision Tree\":\n",
        "        common_params_sel = common_params_tree\n",
        "    else:\n",
        "        common_params_sel = common_params\n",
        "    \n",
        "    # run the learning curve for the classifier\n",
        "    train_size_abs, train_scores, test_scores = learning_curve(clf, **common_params_sel)\n",
        "\n",
        "    # add the scores to the results DataFrame\n",
        "    results_df.loc[len(results_df)-1, \"Train Size\"] = train_size_abs[-1]\n",
        "    results_df.loc[len(results_df)-1, \"Train Score\"] = train_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Train Score Std\"] = np.std(train_scores[-1, :])\n",
        "    results_df.loc[len(results_df)-1, \"Test Score\"] = test_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Test Score Std\"] = np.std(test_scores[-1, :])\n",
        "\n",
        "# print the results DataFrame\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkU6O3OG1B2o",
        "outputId": "e3378917-82fa-498c-c4c8-0d1b955a8190"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on: Decision Tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2b380b174415>:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on: Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2b380b174415>:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on: Linear SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2b380b174415>:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on: SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2b380b174415>:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Classifier Train Size Train Score Train Score Std Test Score  \\\n",
            "0  Decision Tree        487    0.634307         0.02066    0.49948   \n",
            "1  Random Forest        487    0.775953        0.019157   0.470664   \n",
            "2     Linear SVM        487    0.763211        0.020088   0.582382   \n",
            "3            SVM        487    0.516072        0.013477   0.510338   \n",
            "\n",
            "  Test Score Std  \n",
            "0       0.075355  \n",
            "1        0.09737  \n",
            "2       0.087411  \n",
            "3       0.054137  \n",
            "      Classifier Train Size Train Score Train Score Std Test Score  \\\n",
            "0  Decision Tree        487    0.634307         0.02066    0.49948   \n",
            "1  Random Forest        487    0.775953        0.019157   0.470664   \n",
            "2     Linear SVM        487    0.763211        0.020088   0.582382   \n",
            "3            SVM        487    0.516072        0.013477   0.510338   \n",
            "\n",
            "  Test Score Std  \n",
            "0       0.075355  \n",
            "1        0.09737  \n",
            "2       0.087411  \n",
            "3       0.054137  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimized classifiers + ENreg**\n"
      ],
      "metadata": {
        "id": "zIoVct4GuaGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "# define f_beta as a scorer\n",
        "# beta < 1 lends more weight to precision, while beta > 1 favors recall\n",
        "f_beta = make_scorer(fbeta_score, beta=2)\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=0, splitter='best', min_weight_fraction_leaf=0.16666666666666666, min_samples_split=2, min_samples_leaf=6, max_features=None, criterion='entropy', class_weight='balanced')\n",
        "l_svm = LinearSVC(random_state=0, tol=100.0, penalty='l1', loss='squared_hinge', intercept_scaling=9, fit_intercept=True, dual=False, class_weight='balanced', C=0.01)\n",
        "#moeten nog aangepast worden naar goede hyperparameters (met goede X_ENreg):\n",
        "svm = svm.SVC(random_state=0, tol=10.0, shrinking=False, probability=True, kernel='poly', gamma='scale', degree=0, coef0=-5, class_weight='balanced', cache_size=363, C=0.001)\n",
        "#Deze staat al wel goed:\n",
        "rf = RandomForestClassifier(random_state=0, warm_start=True, oob_score=True, n_estimators=795, min_weight_fraction_leaf=0.14583333333333331, min_samples_split=9, min_samples_leaf=5, max_features='log2', criterion='gini', class_weight='balanced', bootstrap=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 6), sharey=True)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": x_ENreg,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"score_type\": \"both\",\n",
        "    \"n_jobs\": 4,\n",
        "    \"line_kw\": {\"marker\": \"o\"},\n",
        "    \"std_display_style\": \"fill_between\",\n",
        "    \"score_name\": \"f2\",\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "title = ['tree', 'RF', 'LSVM', 'SVM']\n",
        "\n",
        "common_params_tree = {\n",
        "    \"X\": x_ENreg,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"score_type\": \"both\",\n",
        "    \"n_jobs\": 4,\n",
        "    \"line_kw\": {\"marker\": \"o\"},\n",
        "    \"std_display_style\": \"fill_between\",\n",
        "    \"score_name\": \"f2\",\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "LearningCurveDisplay.from_estimator(tree, **common_params_tree, ax=ax[0])\n",
        "handles, label = ax[0].get_legend_handles_labels()\n",
        "ax[0].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
        "ax[0].set_title(f\"Learning Curve for {title[0]}\")\n",
        "\n",
        "for ax_idx, estimator in enumerate([rf, l_svm, svm],1):\n",
        "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
        "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
        "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
        "    ax[ax_idx].set_title(f\"Learning Curve for {title[ax_idx]}\")"
      ],
      "metadata": {
        "id": "EdoW2rKV_cEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "from functools import partial\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "f_beta = make_scorer(fbeta_score, beta=2)\n",
        "# f2_scorer = make_scorer(partial(fbeta_score, beta=2), greater_is_better=True)\n",
        "tree = DecisionTreeClassifier(splitter='best', min_weight_fraction_leaf=0.16666666666666666, min_samples_split=2, min_samples_leaf=6, max_features=None, criterion='entropy', class_weight='balanced')\n",
        "l_svm = LinearSVC(random_state=0, tol=100.0, penalty='l1', loss='squared_hinge', intercept_scaling=9, fit_intercept=True, dual=False, class_weight='balanced', C=0.01)\n",
        "#moeten nog aangepast worden naar goede hyperparameters (met goede X_ENreg):\n",
        "svm = svm.SVC(random_state=0, tol=10.0, shrinking=False, probability=True, kernel='poly', gamma='scale', degree=0, coef0=-5, class_weight='balanced', cache_size=363, C=0.001)\n",
        "#Deze staat al wel goed:\n",
        "rf = RandomForestClassifier(random_state=0, warm_start=True, oob_score=True, n_estimators=795, min_weight_fraction_leaf=0.14583333333333331, min_samples_split=9, min_samples_leaf=5, max_features='log2', criterion='gini', class_weight='balanced', bootstrap=True)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": x_ENreg,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"n_jobs\": 4,\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "# create a list of tuples containing classifier names and their instances\n",
        "classifiers = [(\"Decision Tree\", tree), (\"Random Forest\", rf), (\"Linear SVM\", l_svm), (\"SVM\", svm)]\n",
        "\n",
        "# create an empty DataFrame to store the results\n",
        "results_df = pd.DataFrame(columns=[\"Classifier\", \"Train Size\", \"Train Score\", \"Test Score\"])\n",
        "\n",
        "# loop through the classifiers\n",
        "for clf_name, clf in classifiers:\n",
        "    # set the name of the classifier in the results DataFrame\n",
        "    results_df.loc[len(results_df)] = [clf_name, 0, 0, 0]\n",
        "\n",
        "    # run the learning curve for the classifier\n",
        "    common_params = {\n",
        "    \"X\": x_ENreg,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"n_jobs\": 4,\n",
        "    \"scoring\": f_beta\n",
        "    }\n",
        "    train_size_abs, train_scores, test_scores = learning_curve(clf, **common_params)\n",
        "\n",
        "    # add the scores to the results DataFrame\n",
        "    results_df.loc[len(results_df)-1, \"Train Size\"] = train_size_abs[-1]\n",
        "    results_df.loc[len(results_df)-1, \"Train Score\"] = train_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Test Score\"] = test_scores[-1, :].mean()\n",
        "\n",
        "# print the results DataFrame\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "TGgMib6qHMw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "from functools import partial\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "f_beta = make_scorer(fbeta_score, beta=2)\n",
        "# f2_scorer = make_scorer(partial(fbeta_score, beta=2), greater_is_better=True)\n",
        "tree = DecisionTreeClassifier(splitter='best', min_weight_fraction_leaf=0.16666666666666666, min_samples_split=2, min_samples_leaf=6, max_features=None, criterion='entropy', class_weight='balanced')\n",
        "l_svm = LinearSVC(random_state=0, tol=100.0, penalty='l1', loss='squared_hinge', intercept_scaling=9, fit_intercept=True, dual=False, class_weight='balanced', C=0.01)\n",
        "#moeten nog aangepast worden naar goede hyperparameters (met goede X_ENreg):\n",
        "svm = svm.SVC(random_state=0, tol=10.0, shrinking=False, probability=True, kernel='poly', gamma='scale', degree=0, coef0=-5, class_weight='balanced', cache_size=363, C=0.001)\n",
        "#Deze staat al wel goed:\n",
        "rf = RandomForestClassifier(random_state=0, warm_start=True, oob_score=True, n_estimators=795, min_weight_fraction_leaf=0.14583333333333331, min_samples_split=9, min_samples_leaf=5, max_features='log2', criterion='gini', class_weight='balanced', bootstrap=True)\n",
        "\n",
        "common_params = {\n",
        "    \"X\": x_ENreg,\n",
        "    \"y\": y_train,\n",
        "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
        "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    \"n_jobs\": 4,\n",
        "    \"scoring\": f_beta\n",
        "}\n",
        "\n",
        "# create a list of tuples containing classifier names and their instances\n",
        "classifiers = [(\"Decision Tree\", tree), (\"Random Forest\", rf), (\"Linear SVM\", l_svm), (\"SVM\", svm)]\n",
        "\n",
        "# create an empty DataFrame to store the results\n",
        "results_df = pd.DataFrame(columns=[\"Classifier\", \"Train Size\", \"Train Score\", \"Train Score Std\", \"Test Score\", \"Test Score Std\"])\n",
        "\n",
        "# loop through the classifiers\n",
        "for clf_name, clf in classifiers:\n",
        "    print(\"working on:\", clf_name)\n",
        "    # set the name of the classifier in the results DataFrame\n",
        "    #new_row = pd.Series([clf_name, 0, 0, 0, 0, 0], index=results_df.columns)\n",
        "    #results_df = results_df.append([clf_name, 0, 0, 0, 0, 0], ignore_index=True)\n",
        "    # pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n",
        "    \n",
        "    # run the learning curve for the classifier\n",
        "    train_size_abs, train_scores, test_scores = learning_curve(clf, **common_params)\n",
        "\n",
        "    # add the scores to the results DataFrame\n",
        "    results_df.loc[len(results_df)-1, \"Train Size\"] = train_size_abs[-1]\n",
        "    results_df.loc[len(results_df)-1, \"Train Score\"] = train_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Train Score Std\"] = np.std(train_scores[-1, :])\n",
        "    results_df.loc[len(results_df)-1, \"Test Score\"] = test_scores[-1, :].mean()\n",
        "    results_df.loc[len(results_df)-1, \"Test Score Std\"] = np.std(test_scores[-1, :])\n",
        "\n",
        "# print the results DataFrame\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "bYSWX2XEvjsc",
        "outputId": "171a5d7e-1c01-4d3b-c265-2ba6fd2fdb00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on: Decision Tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-119-fadae97e9397>:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on: Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-119-fadae97e9397>:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on: Linear SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-119-fadae97e9397>:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on: SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-119-fadae97e9397>:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\"Classifier\": clf_name, \"Train Size\": 0, \"Train Score\": 0, \"Train Score Std\": 0, \"Test Score\": 0, \"Test Score Std\": 0}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Classifier Train Size Train Score Train Score Std Test Score  \\\n",
            "0  Decision Tree        487    0.672439        0.019595   0.497425   \n",
            "1  Random Forest        487     0.82761        0.016487   0.582964   \n",
            "2     Linear SVM        487    0.796826        0.021337   0.709313   \n",
            "3            SVM        487    0.516072        0.013477   0.510338   \n",
            "\n",
            "  Test Score Std  \n",
            "0       0.072223  \n",
            "1       0.102415  \n",
            "2       0.072487  \n",
            "3       0.054137  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outer cross validation"
      ],
      "metadata": {
        "id": "o8zXm3vHjifh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#univariate LSM bepalen wat f2 scores zijn op testset (met inner of outer kruisvalidatie met test set)\n",
        "x_train, x_val, y_train, y_val = model_selection.train_test_split(x_dropped, y_dropped,test_size=0.25,random_state=0,stratify=y_dropped)\n"
      ],
      "metadata": {
        "id": "7BHmjhgbjebU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}